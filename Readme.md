# Code Carol

> **Hub de evaluaci√≥n integral para medir, estandarizar y potenciar el conocimiento t√©cnico en moldeo por inyecci√≥n.**
> Soluciona la falta de m√©tricas objetivas en la competencia del personal, transformando el "sentimiento" operativo en datos accionables para reducir scrap, mejorar el OEE y garantizar la seguridad.

## üìã Tabla de Contenidos

1. [Objetivo del Proyecto](#-objetivo-del-proyecto)
2. [Gu√≠a de Uso](#-gu√≠a-de-uso)
3. [Estructura del Repositorio](#-estructura-del-repositorio)
4. [Ejemplos de Resultados](#-ejemplos-de-resultados)
5. [KPIs Relevantes](#-kpis-relevantes)
6. [Documentaci√≥n Vinculada](#-documentaci√≥n-vinculada)
7. [Contribuci√≥n](#-contribuci√≥n)
8. [Cr√©ditos y Autores](#-cr√©ditos-y-autores)
9. [Licencia y √âtica](#-licencia-y-√©tica)
10. [Actualizaciones](#-actualizaciones)

---

## üéØ Objetivo del Proyecto

Este repositorio act√∫a como un **n√∫cleo central de evaluaci√≥n (Assessment Hub)**. Su prop√≥sito va m√°s all√° de un simple examen; es una herramienta de diagn√≥stico y mejora continua dise√±ada para:

1.  **Medir el Nivel de Competencia Real:** Evaluar objetivamente al personal operativo, t√©cnico y de ingenier√≠a mediante un sistema de puntuaci√≥n ponderado (Te√≥rico vs. Pr√°ctico).
2.  **Identificar Brechas de Conocimiento:** Detectar √°reas espec√≠ficas de debilidad (ej. Reolog√≠a, Seguridad, Defectos) para dirigir la capacitaci√≥n.
3.  **Base de Datos para Entrenamiento:** Generar inputs para planes de "Upskilling" personalizados.
4.  **Evoluci√≥n de KPIs:** Correlacionar el incremento del conocimiento t√©cnico con la mejora de indicadores de planta (Scrap, OEE) en un horizonte de 12 meses.

**Alcance (Scope):**
*   **Incluye:** Evaluaciones t√©cnicas (Nivel 1, 2 y 3), l√≥gica de puntuaci√≥n, bancos de preguntas (JSON) y gu√≠as de implementaci√≥n.
*   **No Incluye:** Software de simulaci√≥n de inyecci√≥n ni control directo de m√°quinas.

---

## üöÄ Gu√≠a de Uso

### Prerrequisitos
*   Python 3.8+ instalado.
*   Instancia de Formbricks activa (VPS).
*   Variables de entorno configuradas (`.env`).

### Instalaci√≥n
1. Clonar el repositorio.
2. Instalar dependencias:
   ```bash
   pip install requests python-dotenv
   ```
3. Configurar tu `.env` bas√°ndote en `.env.example`.

### Sincronizaci√≥n con Formbricks
Para enviar las evaluaciones a tu instancia de Formbricks, ejecuta:
```bash
python src/sync_to_formbricks.py
```
Este script transformar√° los JSON maestros en encuestas listas para usar en tu VPS: `https://feedback.soul23.cloud`.

## üõ†Ô∏è Integraci√≥n con Formbricks API

Este proyecto utiliza la [Management API de Formbricks](https://formbricks.com/docs/api-reference/management-api--survey/create-survey) para automatizar la creaci√≥n de evaluaciones.

**Caracter√≠sticas de la integraci√≥n:**
- **Localizaci√≥n Autom√°tica:** El script envuelve los textos en el formato `{"default": "..."}` requerido.
- **Estructura Din√°mica:** Soporta preguntas de opci√≥n m√∫ltiple (`multipleChoiceSingle`) y texto abierto.
- **Pantallas Personalizadas:** Incluye autom√°ticamente una *Welcome Card* y una *End Screen* profesional.

---

## üìÇ Estructura del Repositorio

```text
/
‚îú‚îÄ‚îÄ docs/                           # Metodolog√≠a y gu√≠as por nivel
‚îú‚îÄ‚îÄ formbricks/                     # JSONs listos para la API de Formbricks
‚îú‚îÄ‚îÄ master_assesment/               # Fuente de verdad de las preguntas (Scoring y Razonamiento)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ sync_to_formbricks.py       # Script de carga a la API
‚îú‚îÄ‚îÄ .env.example                    # Plantilla de configuraci√≥n
‚îî‚îÄ‚îÄ Readme.md                       # Este archivo
```

---

## üìä Ejemplos de Resultados

Un reporte de evaluaci√≥n t√≠pico genera los siguientes outputs para an√°lisis:

### Ejemplo de Output Individual
```json
{
  "candidato": "Tech_01",
  "nivel": "Nivel 2 - Medio",
  "score_total": 82.5,
  "resultado": "APROBADO",
  "breakdown": {
    "Seguridad": "100% (Excelente)",
    "Procesos": "65% (Requiere Atenci√≥n)",
    "Defectos": "90% (Bueno)"
  },
  "recomendacion": "Reforzar capacitaci√≥n en Variables de Proceso (VPT, Coj√≠n)."
}
```

### Impacto Esperado (Antes vs. Despu√©s)
| M√©trica | Antes del Training | 12 Meses Post-Training |
| :--- | :---: | :---: |
| **Nivel Promedio Equipo** | 45% (B√°sico) | 85% (Medio-Alto) |
| **Tiempo de Cambio (SMED)** | 45 min | 28 min |
| **Scrap Rate** | 3.5% | 1.8% |

---

## üìà KPIs Relevantes

El √©xito de este assessment se mide a trav√©s de indicadores de planta reales.

| KPI | Definici√≥n | Por qu√© importa |
| :--- | :--- | :--- |
| **OEE (Overall Equipment Effectiveness)** | Disponibilidad x Rendimiento x Calidad. | Indica la eficiencia real. Personal capacitado reduce paros menores. |
| **Scrap Rate** | (Piezas defectuosas / Total producidas) * 100. | Directamente relacionado con la habilidad de troubleshooting del t√©cnico. |
| **Cycle Time Efficiency** | Tiempo ciclo real vs. Est√°ndar. | El conocimiento avanzado permite optimizar el ciclo sin sacrificar calidad. |
| **MTTR (Mean Time To Repair)** | Tiempo promedio para solucionar una falla. | T√©cnicos competentes diagnostican la causa ra√≠z m√°s r√°pido. |
| **Skill Gap Index** | % de brecha entre el skill ideal y el real. | M√©trica directa de RRHH para medir la efectividad del programa. |

---

## üìö Documentaci√≥n Vinculada

Para profundizar en √°reas espec√≠ficas, consulta:

*   **[Metodolog√≠a de Evaluaci√≥n](docs/metodology.md):** Detalle del sistema de puntos (Score Te√≥rico vs Pr√°ctico).
*   **[Nivel 1 - B√°sico](docs/questions/LEVEL_1_BASIC_ASSESSMENT.md):** Temario para operadores.
*   **[Nivel 2 - Medio](docs/questions/LEVEL_2_MEDIUM_ASSESSMENT.md):** Temario para t√©cnicos.
*   **[Nivel 3 - Avanzado](docs/questions/LEVEL_3_ADVANCED_ASSESSMENT.md):** Temario para ingenier√≠a.
*   **[Razonamiento y Prop√≥sito](docs/RAZONAMIENTO_Y_PROPOSITO.md):** El "Por qu√©" del proyecto.

---

## ü§ù Contribuci√≥n

¬°Las contribuciones son bienvenidas para mantener el banco de preguntas actualizado y relevante!

1.  **Fork** este repositorio.
2.  Crea una rama para tu feature (`git checkout -b feature/nueva-pregunta-nivel-2`).
3.  Agrega tus preguntas al JSON correspondiente siguiendo el esquema existente.
4.  Haz **Commit** de tus cambios.
5.  Abre un **Pull Request**.

Por favor, aseg√∫rate de que las nuevas preguntas tengan una respuesta t√©cnica verificable y un razonamiento claro.

---

## üë• Cr√©ditos y Autores

Este proyecto ha sido posible gracias a la colaboraci√≥n multidisciplinaria:

*   **Fortunato Salazar:** Idea original, dise√±o de cuestionarios y definici√≥n de m√©tricas de evaluaci√≥n.
*   **Marco Gallegos:** Optimizaci√≥n de cuestionarios, desarrollo del sistema de automatizaci√≥n (formas) y an√°lisis de datos.

---

## ‚öñÔ∏è Licencia y √âtica

**Licencia:** Este proyecto se distribuye bajo la licencia MIT (o la que aplique al proyecto privado).
**C√≥digo de Conducta:** Se espera que todos los colaboradores mantengan un ambiente de respeto profesional. El objetivo es educar y mejorar, no juzgar.

---

## üîÑ Actualizaciones

*   **√öltima actualizaci√≥n:** 25 de Diciembre, 2025.
*   **Versi√≥n actual:** v2.0 (Estructura JSON y Gu√≠as Markdown completas).